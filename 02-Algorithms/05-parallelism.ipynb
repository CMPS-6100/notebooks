{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelism\n",
    "\n",
    "More efficient algorithms are more powerful algorithms in that they can solve larger problems. Many of our world's most important problems require tremendous computational power, more than any individual CPU could provide in any reasonable timeframe. \n",
    "\n",
    "A parallel algorithm is one in which independent parts of the problem can be solved concurrently and their solutions combined into a final solution. Parallel algorithms spread their work over multiple CPU cores, allowing computational resources to be used more effectively and larger problems to be solved.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "### Independence\n",
    "\n",
    "The idea of **independence** is crucial for parallel algorithms. For an algorithm to be parallelizable, it must contain parts which can be solved concurrently. If two parts of an algorithm depend on each other, then they must be executed one after another, limiting parallelizability. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Work\n",
    "\n",
    "The **work** of an algorithm is our standard runtime. An algorithm's work is the total number of operations required as a function of the problem size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Span\n",
    "\n",
    "The **span** of an algorithm is a measure of how much dependency if built into an algorithm. An algorithm's span is the length of the longest chain of dependent operations.\n",
    "\n",
    "Since dependency limits parallelizability, the larger the span, the less parallelizable an algorithm is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Parallelism\n",
    "\n",
    "The parallelism of an algorithm is defined as:\n",
    "\n",
    "$\\text{parallelism} = \\frac{\\text{work}}{\\text{span}}$\n",
    "\n",
    "The smaller the span is with relation to the total work required, the more parallelizable an algorithm is.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursively Searching through a list\n",
    "\n",
    "In the last set of you notes, you considered a recursive implementation of linear search, now let's consider a second recusive solution to the searching problem.\n",
    "\n",
    "To be specific, the problem being solved is:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The Search Problem\n",
    "\n",
    "Given an unsorted list and a key, return `True` if the key is in the list and `False` otherwise.\n",
    "\n",
    "#### Strategy\n",
    "\n",
    "In linear search, we look through the list element by element to see if any of them match the key.\n",
    "\n",
    "Instead of scanning element by element, we can use a divide and conquer approach. \n",
    "\n",
    "The basic idea is:\n",
    "\n",
    "> If the key is in the left half **or** if the key is in the right half, then it is in the list.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide and Conquer Search Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_DC(lst, key):\n",
    "    if len(lst) == 0:\n",
    "        return False\n",
    "    if len(lst) == 1:\n",
    "        return lst[0] == key\n",
    "\n",
    "    mid = len(lst)//2\n",
    "    return search_DC(lst[:mid], key) or search_DC(lst[mid:], key)\n",
    "\n",
    "lst = [4, 5, 2, 6, 1, 0, 3, 7]\n",
    "search_DC(lst, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel Implementation?\n",
    "\n",
    "The details of how to implement parallel programs are beyond the scope of this material, but to show that it is possible, a parallel implemenation is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "def search_DC(lst, key):\n",
    "    if len(lst) == 0:\n",
    "        return False\n",
    "    if len(lst) == 1:\n",
    "        return lst[0] == key\n",
    "\n",
    "    mid = len(lst)//2\n",
    "    with ThreadPool(2) as pool:\n",
    "        # launch the first recursive call\n",
    "        result1 = pool.apply_async(search_DC, [lst[:mid], key])\n",
    "        # launch the second recursive call\n",
    "        result2 = pool.apply_async(search_DC, [lst[mid:], key])\n",
    "        return result1.get() or result2.get() # wait for both to finish and return the answer\n",
    "\n",
    "lst = [4, 5, 2, 6, 1, 0, 3, 7]\n",
    "search_DC(lst, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, parallelizing our implementation adds some complexity and clutter.\n",
    "\n",
    "In order to better focus on the algorithms themselves, we will omit the actual parallelization in our implementations. In our future analysis however, we will assume that the algorithm has been parallelized. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In a future module, we will discuss threads and concurrency."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Algorithm Analysis\n",
    "\n",
    "To analyze `search_DC`, we need to determine its work and span.\n",
    "\n",
    "First, let's think about its overall behavior.\n",
    "\n",
    "At every step, it divides the list into two halves and recursively runs `search_DC` on each. Once the lists get down to be lists of size 1, it starts evaluating the base cases and combining results the results (through that **or** statement).\n",
    "\n",
    "We can visualize it as the following computation graph:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"figures/search_recursive.jpeg\" width = \"100%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work\n",
    "\n",
    "The work of the algorithm is the total work done across all function calls.\n",
    "\n",
    "Since every call performs constant work (two conditional checks, the calculation of mid, and the `or` in the return), the total work is just the total number of calls.\n",
    "\n",
    "We can observe that the number of function calls is the number of nodes in the **divide** and **base cases** in the computation graph.\n",
    "\n",
    "We can also observe that they form a perfect binary tree, that is, a binary tree where the bottom level is full.\n",
    "\n",
    "Drawn more abstractly:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"figures/binary_tree.jpeg\" width = \"75%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given its regularity, we can easily calculate the number of nodes in it.\n",
    "\n",
    "For any perfect binary tree, the total number of nodes is:\n",
    "\n",
    "$2*\\text{num\\_leaves}-1$\n",
    "\n",
    "where the leaves are the nodes along the bottom of the tree. How many leaves do we have?\n",
    "\n",
    "Recalling from up above, the leaves correspond to the base cases, and we will have one base case for every element in the list. Thus the number of leaves will be $n$, and the total **work** will be:\n",
    "\n",
    "$2n-1 \\in O(n)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Span\n",
    "\n",
    "What about the span?\n",
    "\n",
    "The span of the algorithm is the length of the longest path through the computation graph.\n",
    "\n",
    "What is the length of the longest path? We can observe that the computation graph is basically two inverted binary trees. We can approximate the length of its longest path as being:\n",
    "\n",
    "$2*\\text{binary\\_tree\\_height}$\n",
    "\n",
    "The height of a perfect binary tree with $n$ nodes is $\\log_2 n$.\n",
    "\n",
    "> Technically, our tree has $2n-1$ nodes so I am being a little loose here, but the difference between $\\log_2 n$ and $\\log_2 2n$ is $1$ and it won't affect our final analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our **span** is thus:\n",
    "\n",
    "$2\\log_2 n \\in O(\\log_2 n)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelism\n",
    "\n",
    "We have calculated our work and span\n",
    "\n",
    "**Work:** $O(n)$\n",
    "\n",
    "**Span:** $O(\\log_2 n)$\n",
    "\n",
    "Since our span is less than the work, we do have some parallelism here.\n",
    "\n",
    "How much?\n",
    "\n",
    "**Parallelism:** $O(\\frac{n}{\\log_2 n})$\n",
    "\n",
    "This is exponential speedup! This is great!\n",
    "\n",
    "By taking a divide and conquer approach and parallelizing the calls, we are able to achieve a great speedup."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We have three important measures for the analysis of parallel algorithms.\n",
    "\n",
    "The **work** of an algorithm is the total number of operations required by the algorithm.\n",
    "\n",
    "The **span** of an algorithm is the length of the longest chain of dependent operations in it.\n",
    "\n",
    "An algorithm's **parallelism** is the amount of speedup possible if it is parallelized. We calculate it as $\\frac{work}{span}$.\n",
    "\n",
    "The lower the span of an algorithm is, as compared to its work, the more parallelizable it it.\n",
    "\n",
    "As we continue to discuss more algorithms, we will analyze both their work and their span so that we can get a handle on how much parallelism is possible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
